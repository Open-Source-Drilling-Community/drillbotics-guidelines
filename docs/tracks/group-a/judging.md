---
tags:
  - group-a
  - judging
---

# Mode Virtual (V) — Judging

!!! info "2025.1 rubric summary"
    See Competition → Rules & Scoring for current 2025.1 weights and the optional Edge-AI Bonus. This page retains 2024 reference tables for context.

!!! tip "Algorithm-agnostic"
    Credit is based on outcomes and evidence; architecture choice (PID/MPC/RL; rules/CNN/LLM) is not scored directly, provided constraints and safety are met.

!!! note "Innovation Uplift"
    Judges may award top-of-band within categories for documented novel contributions (hardware, sensing, control, HF/UX, data tooling, compression/efficiency) that improve outcomes, safety, or clarity. This does not exceed category maxima.

!!! note "Small multimodal LLMs encouraged"
    Teams may prototype with larger cloud models, but final deliverables and performance are evaluated using small, locally run models under limited inference hardware (e.g., ≤2 vCPU or ≤20 W GPU, ≤4–8 GB RAM, ≤10 min compute time (non-llm) or ≤8 vCPU ≤1,150 W GPU, ≤16–64 GB RAM (LLM) ≤15 min inference runtime). All AI runs must be offline during judging.

Scoring criteria are defined in the 2024 guidelines and differ slightly by challenge. Judges may award bonus points for “above and beyond” achievements.


